<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2018/19 on Marc Deisenroth</title><link>https://deisenroth.cc/teaching/2018-19/</link><description>Recent content in 2018/19 on Marc Deisenroth</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 03 Aug 2019 14:05:33 +0100</lastBuildDate><atom:link href="https://deisenroth.cc/teaching/2018-19/index.xml" rel="self" type="application/rss+xml"/><item><title>Probabilistic Inference (2018/19)</title><link>https://deisenroth.cc/teaching/2018-19/probabilistic-inference/</link><guid>https://deisenroth.cc/teaching/2018-19/probabilistic-inference/</guid><description>&lt;h2 id="imperial-college-london-co-493">Imperial College London (CO-493)&lt;/h2>
&lt;h3 id="course-outline">Course Outline&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/graphical-models.pdf">Graphical models&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/gaussian-processes.pdf">Gaussian processes&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/bayesian-optimization.pdf">Bayesian optimization&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/logistic-regression.pdf">Logistic regression&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/sampling.pdf">Sampling&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/variational-inference.pdf">Variational inference&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/sparse-gaussian-processes.pdf">Sparse Gaussian processes&lt;/a> (slides by Hugh Salimbeni)&lt;/li>
&lt;/ul>
&lt;h3 id="other-material">Other Material&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/logistics.pdf">Logistics&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="lectures">Lectures&lt;/h3>
&lt;ul>
&lt;li>Tuesdays, 16:00 - 18:00 (Huxley, 308)&lt;/li>
&lt;li>Fridays, 11:00 - 13:00 (Huxley, 340)&lt;/li>
&lt;/ul>
&lt;h3 id="tutorials">Tutorials&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/gp-tutorial.ipynb">Gaussian Processes&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/bayesian-optimization-tutorial.ipynb">Bayesian Optimization&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/probabilistic-inference/variational-inference-tutorial.ipynb">Variational Inference&lt;/a> (ipynb)&lt;/li>
&lt;/ul>
&lt;h3 id="coursework">Coursework&lt;/h3>
&lt;ul>
&lt;li>Coursework 1: Gaussian processes&lt;/li>
&lt;li>Coursework 2: Logistic regression and MCMC&lt;/li>
&lt;li>Coursework 3: Variational inference&lt;/li>
&lt;/ul>
&lt;h3 id="test">Test&lt;/h3>
&lt;p>Graphical models&lt;/p>
&lt;h3 id="references">References&lt;/h3>
&lt;ul>
&lt;li>Bishop: &lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf" target="_blank" rel="noopener">Pattern Recognition and Machine Learning&lt;/a>&lt;/li>
&lt;li>Rasmussen &amp;amp; Williams: &lt;a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" target="_blank" rel="noopener">Gaussian Processes for Machine Learning&lt;/a>&lt;/li>
&lt;li>Deisenroth et al.: &lt;a href="https://mml-book.com" target="_blank" rel="noopener">Mathematics for Machine Learning&lt;/a> (background reading)&lt;/li>
&lt;/ul>
&lt;h3 id="teaching-assistants">Teaching Assistants&lt;/h3>
&lt;ul>
&lt;li>Ian Walker&lt;/li>
&lt;li>Kenneth Co&lt;/li>
&lt;li>Linh Tran&lt;/li>
&lt;li>Nick Pawlowski&lt;/li>
&lt;li>Sanket Kamthe&lt;/li>
&lt;li>Steindor Saemundsson&lt;/li>
&lt;/ul></description></item><item><title>Foundations of Machine Learning (2018/19)</title><link>https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/</link><guid>https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/</guid><description>&lt;h2 id="african-institute-for-mathematical-sciences-kigali-rwanda">African Institute for Mathematical Sciences, Kigali, Rwanda&lt;/h2>
&lt;p>This course was part of the &lt;a href="https://aimsammi.org/" target="_blank" rel="noopener">African Masters in Machine Intelligence (AMMI)&lt;/a> at the &lt;a href="https://www.aims.ac.rw/" target="_blank" rel="noopener">African Institute for Mathematical Sciences (AIMS), Rwanda&lt;/a>.&lt;/p>
&lt;h3 id="part-1-mathematical-foundations">Part 1: Mathematical Foundations&lt;/h3>
&lt;ul>
&lt;li>Linear Algebra (&lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 2)
&lt;ul>
&lt;li>Groups&lt;/li>
&lt;li>Vector spaces&lt;/li>
&lt;li>Linear independence&lt;/li>
&lt;li>Basis&lt;/li>
&lt;li>Coordinate representation&lt;/li>
&lt;li>Basis change&lt;/li>
&lt;li>Linear mappings&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Analytic Geometry (&lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 3)
&lt;ul>
&lt;li>Eigenvalues&lt;/li>
&lt;li>Norms and inner products&lt;/li>
&lt;li>Distances and angles&lt;/li>
&lt;li>Orthogonal projections&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Vector Calculus (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_vector_calculus.pdf">slides&lt;/a>, &lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 5)
&lt;ul>
&lt;li>Scalar differentiation&lt;/li>
&lt;li>Partial derivatives&lt;/li>
&lt;li>Jacobian&lt;/li>
&lt;li>Chain rule&lt;/li>
&lt;li>Derivatives of matrices w.r.t. matrices&lt;/li>
&lt;li>Gradients in a multi-layer neural network&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Statistics and Probability Theory (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_statistics_and_probability.pdf">slides&lt;/a>, &lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 6)
&lt;ul>
&lt;li>Statistics to describe datasets: means, variances, covariances, medians&lt;/li>
&lt;li>Basic probability distributions: Bernoulli, Binomial, Beta, Gaussian, Gamma&lt;/li>
&lt;li>Parameter estimation (maximum likelihood, MAP estimation)&lt;/li>
&lt;li>Key concepts in probability theory&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Optimization (&lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 7)
&lt;ul>
&lt;li>Gradient descent&lt;/li>
&lt;li>Stochastic gradient descent&lt;/li>
&lt;li>Momentum&lt;/li>
&lt;li>Constrained optimization&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="part-2-machine-learning">Part 2: Machine Learning&lt;/h3>
&lt;ul>
&lt;li>Graphical Models (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_graphical_models.pdf">slides&lt;/a>, &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/Bishop-PRML-sample.pdf" target="_blank" rel="noopener">Chris Bishop&amp;rsquo;s book chapter&lt;/a>)
&lt;ul>
&lt;li>Directed graphical models&lt;/li>
&lt;li>Undirected graphical models&lt;/li>
&lt;li>D-separation&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Dimensionality Reduction with Principal Component Analysis (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_pca.pdf">slides&lt;/a>, &lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 10)
&lt;ul>
&lt;li>Maximum variance perspective&lt;/li>
&lt;li>Projection perspective&lt;/li>
&lt;li>Key steps of PCA in practice&lt;/li>
&lt;li>Probabilistic PCA&lt;/li>
&lt;li>Other perspectives of PCA&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Linear Regression (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_linear_regression.pdf">slides&lt;/a>, &lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 9)
&lt;ul>
&lt;li>Maximum likelihood estimation&lt;/li>
&lt;li>Maximum a posteriori estimation&lt;/li>
&lt;li>Bayesian linear regression&lt;/li>
&lt;li>Distribution over functions&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Model Selection (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_model_selection.pdf">slides&lt;/a>, &lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 8)
&lt;ul>
&lt;li>Cross validation&lt;/li>
&lt;li>Information criteria&lt;/li>
&lt;li>Bayesian model selection&lt;/li>
&lt;li>Occam&amp;rsquo;s razor and the marginal likelihood&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Gaussian Process Regression (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_gaussian_processes.pdf">slides&lt;/a>, &lt;a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" target="_blank" rel="noopener">GPML book&lt;/a>)
&lt;ul>
&lt;li>Model&lt;/li>
&lt;li>Inference with Gaussian processes&lt;/li>
&lt;li>Training via evidence maximization&lt;/li>
&lt;li>Model selection&lt;/li>
&lt;li>Interpreting the hyper-parameters&lt;/li>
&lt;li>Practical tips and tricks when working with Gaussian processes&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Bayesian Optimization (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_bayesian_optimization.pdf">slides&lt;/a>)
&lt;ul>
&lt;li>Optimization of meta-parameters in machine learning systems&lt;/li>
&lt;li>Acquisition functions&lt;/li>
&lt;li>Practicalities&lt;/li>
&lt;li>Applications&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Sampling (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_sampling.pdf">slides&lt;/a>)
&lt;ul>
&lt;li>Monte Carlo estimation&lt;/li>
&lt;li>Importance sampling&lt;/li>
&lt;li>Rejection sampling&lt;/li>
&lt;li>Metropolis Hastings&lt;/li>
&lt;li>Slice sampling&lt;/li>
&lt;li>Gibbs sampling&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Density Estimation with Gaussian Mixture Models (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_gmm.pdf">slides&lt;/a>, &lt;a href="https://mml-book.com" target="_blank" rel="noopener">MML book&lt;/a> chapter 11)
&lt;ul>
&lt;li>Mixture models&lt;/li>
&lt;li>Parameter estimation&lt;/li>
&lt;li>Implementation&lt;/li>
&lt;li>Latent variable perspective&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Classification with Logistic Regression (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_logistic_regression.pdf">slides&lt;/a>)
&lt;ul>
&lt;li>Logistic sigmoid and as a posterior class probability&lt;/li>
&lt;li>Implicit modeling assumptions&lt;/li>
&lt;li>Maximum likelihood estimation&lt;/li>
&lt;li>MAP estimation&lt;/li>
&lt;li>Probabilistic model&lt;/li>
&lt;li>Laplace approximation&lt;/li>
&lt;li>Bayesian logistic regression&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Information Theory (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_information_theory.pdf">slides&lt;/a> by Pedro Mediano)
&lt;ul>
&lt;li>Entropy&lt;/li>
&lt;li>KL divergence&lt;/li>
&lt;li>Mutual information&lt;/li>
&lt;li>Coding theory&lt;/li>
&lt;li>Information theory and statistical inference&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Variational Inference (&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/lecture_variational_inference.pdf">slides&lt;/a>)
&lt;ul>
&lt;li>Inference as optimization&lt;/li>
&lt;li>Evidence lower bound&lt;/li>
&lt;li>Conditionally conjugate models&lt;/li>
&lt;li>Mean-field variational inference in conditionally conjugate models&lt;/li>
&lt;li>Black-box variational inference for hierarchical Bayesian models&lt;/li>
&lt;li>Gradient estimators&lt;/li>
&lt;li>Amortized inference&lt;/li>
&lt;li>Richer posteriors&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="practicals">Practicals&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/template_statistics_of_datasets.ipynb">Statistics of datasets&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/template_distances_and_angles.ipynb">Angles and distances between images&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/template_projections.ipynb">Orthogonal projections&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/template_pca.ipynb">Principal component analysis&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/tutorial_linear_regression.ipynb">Linear regression&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/GPSS_Lab1_2018.ipynb">Gaussian processes&lt;/a> (ipynb, from GP summer school)&lt;/li>
&lt;li>Sampling&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/tutorial_gmm.template.ipynb">Gaussian mixture models&lt;/a> (ipynb)&lt;/li>
&lt;li>&lt;a href="https://deisenroth.cc/teaching/2018-19/foundations-of-machine-learning/tutorial_logistic_regression.ipynb">Logistic regression&lt;/a> (ipynb)&lt;/li>
&lt;/ul>
&lt;h3 id="references">References&lt;/h3>
&lt;ul>
&lt;li>Deisenroth et al.: &lt;a href="https://mml-book.com" target="_blank" rel="noopener">Mathematics for Machine Learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/learn/pca-machine-learning" target="_blank" rel="noopener">Coursera course&lt;/a> on empirical statistics, inner products, orthogonal projections and PCA&lt;/li>
&lt;li>Bishop: &lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf" target="_blank" rel="noopener">Pattern Recognition and Machine Learning&lt;/a>, 2006&lt;/li>
&lt;li>MacKay: &lt;a href="https://www.inference.org.uk/itprnn/book.pdf" target="_blank" rel="noopener">Information Theory, Inference, and Learning Algorithms&lt;/a>, 2003&lt;/li>
&lt;li>Strang: Introduction to Linear Algebra&lt;/li>
&lt;/ul>
&lt;h3 id="team">Team&lt;/h3>
&lt;ul>
&lt;li>Marc Deisenroth (Lecturer)&lt;/li>
&lt;li>Kossi Amouzouvi (Tutor, AIMS Rwanda)&lt;/li>
&lt;li>Oluwafemi Azeez (Tutor, CMU Africa)&lt;/li>
&lt;li>Steindór Sæmundsson (Tutor, Imperial College London)&lt;/li>
&lt;li>Pedro Martinez Mediano (Tutor, Imperial College London)&lt;/li>
&lt;/ul></description></item></channel></rss>